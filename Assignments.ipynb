{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing course assignments\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import asc, lit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conf = SparkConf().setAppName('Assignment').setMaster('local')\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing `SparkSession`, it is a combination of the previous versions `SparkConf`, `SparkContext`, `SQLContext`, and `HiveContext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.\n",
    "#### Leer el archivo data/containers.csv y contar el número de líneas.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniendo los datos del archivo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mAssignments.ipynb\u001b[0m*  \u001b[34;42mdata_processing_course-master\u001b[0m/  \u001b[34;42mspark-warehouse\u001b[0m/\r\n",
      "\u001b[01;32mcontainers.csv\u001b[0m*     \u001b[01;32mPySpark.ipynb\u001b[0m*                  \u001b[34;42mtextMining\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/work/data_processing_course-master/assignments/data/containers.csv\"\n",
    "csvdata = spark.read.format(\"csv\").option(\"header\", \"false\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='ship_imo;ship_name;country;departure;container_id;container_type;container_group;net_weight;gross_weight;owner;declared;contact;customs_ok'),\n",
       " Row(_c0='AMC1861710;Jayden;BD;201602183;FCUK1755843;4960;28VH;44804866.62;2240243.33;Streich-Wilkinson;Music')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobando obtención de los datos.\n",
    "csvdata.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contando el número de líneas del archivo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvdata.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.\n",
    "#### Leer el archivo data/containers.csv y filtrar aquellos contenedores cuyo ship_imo es DEJ1128330 y el grupo del contenedor es 22P1. Guardar los resultados en un archivo de texto en resultados/resutado_2.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['ship_imo',\n",
       "  'ship_name',\n",
       "  'country',\n",
       "  'departure',\n",
       "  'container_id',\n",
       "  'container_type',\n",
       "  'container_group',\n",
       "  'net_weight',\n",
       "  'gross_weight',\n",
       "  'owner',\n",
       "  'declared',\n",
       "  'contact',\n",
       "  'customs_ok'],\n",
       " ['AMC1861710',\n",
       "  'Jayden',\n",
       "  'BD',\n",
       "  '201602183',\n",
       "  'FCUK1755843',\n",
       "  '4960',\n",
       "  '28VH',\n",
       "  '44804866.62',\n",
       "  '2240243.33',\n",
       "  'Streich-Wilkinson',\n",
       "  'Music']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(csvdata))\n",
    "datardd = csvdata.rdd\n",
    "print(type(datardd))\n",
    "\n",
    "datasplit = datardd.map(lambda row: row[0].split(\";\"))\n",
    "\n",
    "datasplit.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ship_imo',\n",
       " 'AMC1861710',\n",
       " 'POG1615575',\n",
       " 'SQH1155999',\n",
       " 'JCI1797526',\n",
       " 'MBV1836745',\n",
       " 'GYR1192020',\n",
       " 'GLV1922612',\n",
       " 'NLH1771681',\n",
       " 'FUS1202266']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datafiltered = datasplit.filter(lambda row: row == '22P1')\n",
    "datasplit.map(lambda row: row[0]).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasplit.filter(lambda row: row[6] == '22P1' and row[0] == 'DEJ1128330').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DEJ1128330',\n",
       "  'Tiara',\n",
       "  'GP',\n",
       "  '2016021818',\n",
       "  'GYFD1228113',\n",
       "  '20PF',\n",
       "  '22P1',\n",
       "  '51503716.88',\n",
       "  '5150371.69',\n",
       "  'Armstrong-Goldner',\n",
       "  'Automotive'],\n",
       " ['DEJ1128330',\n",
       "  'Tiara',\n",
       "  'GP',\n",
       "  '2016021818',\n",
       "  'MBPF1909627',\n",
       "  '24H2',\n",
       "  '22P1',\n",
       "  '37266600.88',\n",
       "  '1863330.04',\n",
       "  'Lehner-Hamill',\n",
       "  'Jewelery']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasplit.filter(lambda row: row[6] == '22P1' and row[0] == 'DEJ1128330').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando los datos como archivo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = datasplit.filter(lambda row: row[6] == '22P1' and row[0] == 'DEJ1128330')\n",
    "x1.saveAsTextFile('data_processing_course-master/assignments/resultados/resultado_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3.\n",
    "#### Leer el archivo data/containers.csv y convertir a formato Parquet. Recuerda que puedes hacer uso de la funcion parse_container en helpers.py tal y como vimos en clase. Guarda los resultados en resultados/resultado_3.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `SparkSession` to create a Dataframe from a csv. I am using a Dataframe instead of a RDD, because are RDDs are schemaless, and Dataframes are close to Parquet files structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3 = spark.read.csv(path, header=True, sep=';') #Usamos el mismo path creado previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------+----------+------------+--------------+---------------+-----------+------------+-----------------+--------------------+--------------------+----------+\n",
      "|  ship_imo|        ship_name|country| departure|container_id|container_type|container_group| net_weight|gross_weight|            owner|            declared|             contact|customs_ok|\n",
      "+----------+-----------------+-------+----------+------------+--------------+---------------+-----------+------------+-----------------+--------------------+--------------------+----------+\n",
      "|AMC1861710|           Jayden|     BD| 201602183| FCUK1755843|          4960|           28VH|44804866.62|  2240243.33|Streich-Wilkinson|Music, Tools, Aut...|octavia@stammbedn...|      true|\n",
      "|POG1615575|Lake Eribertoland|     CR|2016021611| PDXW1549639|          28VH|           8888|16681047.32|   500431.42|  Senger and Sons|   Movies & Jewelery|cindy.dubuque@rob...|      true|\n",
      "|SQH1155999|           Aileen|     GN| 201602191| PLKO1661930|          L2R3|           L5R1|69102632.38|  3455131.62| Thompson-Kautzer|   Movies & Jewelery|otha@granteichman...|      true|\n",
      "+----------+-----------------+-------+----------+------------+--------------+---------------+-----------+------------+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/data_processing_course-master/assignments/resultados\n"
     ]
    }
   ],
   "source": [
    "cd data_processing_course-master/assignments/resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3.write.parquet(\"data_processing_course-master/assignments/resultados/resultado_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4.\n",
    "#### Lee el archivo de Parquet guardado en el ejercicio 3 y filtra los barcos que tienen al menos un contenedor donde la columna customs_ok es igual a false. Extrae una lista con los identificadores de barco, ship_imo, sin duplicados y ordenados alfabéticamente, en formato json.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4 = spark.read.parquet(\"data_processing_course-master/assignments/resultados/resultado_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ship_imo',\n",
       " 'ship_name',\n",
       " 'country',\n",
       " 'departure',\n",
       " 'container_id',\n",
       " 'container_type',\n",
       " 'container_group',\n",
       " 'net_weight',\n",
       " 'gross_weight',\n",
       " 'owner',\n",
       " 'declared',\n",
       " 'contact',\n",
       " 'customs_ok']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  ship_imo|\n",
      "+----------+\n",
      "|KSP1096387|\n",
      "|GYR1192020|\n",
      "|JET1053895|\n",
      "|SQH1155999|\n",
      "|NLH1771681|\n",
      "|JCI1797526|\n",
      "|GEU1548633|\n",
      "|AEY1108363|\n",
      "|IWE1254579|\n",
      "|AMC1861710|\n",
      "|POG1615575|\n",
      "|MBV1836745|\n",
      "|GLV1922612|\n",
      "|YZX1455509|\n",
      "|TCU1641123|\n",
      "|JMP1637582|\n",
      "|DEJ1128330|\n",
      "|RYP1117603|\n",
      "|FUS1202266|\n",
      "|NCZ1777367|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT ship_imo FROM data WHERE customs_ok = 'false'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4 = spark.sql(\"SELECT DISTINCT ship_imo FROM data WHERE customs_ok = 'false'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT ship_imo FROM data WHERE customs_ok = 'false'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ship_imo='AEY1108363'),\n",
       " Row(ship_imo='AMC1861710'),\n",
       " Row(ship_imo='DEJ1128330'),\n",
       " Row(ship_imo='FUS1202266'),\n",
       " Row(ship_imo='GEU1548633'),\n",
       " Row(ship_imo='GLV1922612'),\n",
       " Row(ship_imo='GYR1192020'),\n",
       " Row(ship_imo='IWE1254579'),\n",
       " Row(ship_imo='JCI1797526'),\n",
       " Row(ship_imo='JET1053895'),\n",
       " Row(ship_imo='JMP1637582'),\n",
       " Row(ship_imo='KSP1096387'),\n",
       " Row(ship_imo='MBV1836745'),\n",
       " Row(ship_imo='NCZ1777367'),\n",
       " Row(ship_imo='NLH1771681'),\n",
       " Row(ship_imo='POG1615575'),\n",
       " Row(ship_imo='RYP1117603'),\n",
       " Row(ship_imo='SQH1155999'),\n",
       " Row(ship_imo='TCU1641123'),\n",
       " Row(ship_imo='YZX1455509')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.sort(asc(\"ship_imo\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4.sort(asc(\"ship_imo\")).write.json(\"data_processing_course-master/assignments/resultados/resultado_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5.\n",
    "#### Crea una UDF para validar el código de identificación del contenedor container_id. Para simplificar la validación, daremos como válidos aquellos códigos compuestos de 3 letras para el propietario, 1 letra para la categoría, 6 números y 1 dígito de control. Devuelve un DataFrame con los campos: ship_imo, container_id, propietario, categoria, numero_serie y digito_control.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|container_id|\n",
      "+------------+\n",
      "| DXTQ1407119|\n",
      "| VXNB1938296|\n",
      "| OVMU1118217|\n",
      "| EAQO1539643|\n",
      "| SGQH1799946|\n",
      "| SWXT1708984|\n",
      "| EDBR1562470|\n",
      "| FCMB1487245|\n",
      "| UBRI1681197|\n",
      "| LFTG1322014|\n",
      "| RAUX1713695|\n",
      "| QKOJ1756061|\n",
      "| JVFH1614514|\n",
      "| KETX1362337|\n",
      "| KUOG1927848|\n",
      "| GSVC1467358|\n",
      "| JXRI1226202|\n",
      "| QZKL1853985|\n",
      "| HDGM1122708|\n",
      "| ZBJH1066313|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT container_id FROM data \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting familiar with Python re package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(container_id='DXTQ1407119'), Row(container_id='VXNB1938296')]\n"
     ]
    }
   ],
   "source": [
    "test5 = spark.sql(\"SELECT DISTINCT container_id FROM data \").take(2)\n",
    "type(test5)\n",
    "type(test5[0])\n",
    "print(str(test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "containeridre = re.search(r'\\w\\w\\w\\w\\d\\d\\d\\d\\d\\d\\d', str(test5[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ez pz\n"
     ]
    }
   ],
   "source": [
    "if containeridre:\n",
    "    print('ez pz')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function to validate container ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validateID(containerID):\n",
    "    containeridre = re.search(r'\\w\\w\\w\\w\\d\\d\\d\\d\\d\\d\\d', str(containerID))\n",
    "    #nonvalid = []\n",
    "    if containeridre:\n",
    "        return(\"Container ID valid\")\n",
    "    else:\n",
    "        #nonvalid.append(str(containerID))\n",
    "        return(\"----- Container ID not valid: \" + str(containerID) + '-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data5 = spark.sql(\"SELECT DISTINCT container_id FROM data \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data5col = data5.select(\"container_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(container_id='DXTQ1407119'), Row(container_id='VXNB1938296')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5col.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Container ID valid'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validateID('DXTQ1407119')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " '----- Container ID not valid: Row(container_id=None)-----',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " \"----- Container ID not valid: Row(container_id='JMYG190Z978')-----\",\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " \"----- Container ID not valid: Row(container_id='GJFL14A2798')-----\",\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " \"----- Container ID not valid: Row(container_id='CTVU1506A832')-----\",\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " \"----- Container ID not valid: Row(container_id='DUKF166276')-----\",\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid',\n",
       " 'Container ID valid']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.rdd.map(lambda row: validateID(str(row))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contenedores que no tienen un código válido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['----- Container ID not valid: Row(container_id=None)-----',\n",
       " \"----- Container ID not valid: Row(container_id='JMYG190Z978')-----\",\n",
       " \"----- Container ID not valid: Row(container_id='GJFL14A2798')-----\",\n",
       " \"----- Container ID not valid: Row(container_id='CTVU1506A832')-----\",\n",
       " \"----- Container ID not valid: Row(container_id='DUKF166276')-----\"]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.rdd.map(lambda row: validateID(str(row))).filter(lambda x: str(x) != 'Container ID valid').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = spark.sql(\"SELECT DISTINCT container_id FROM data \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-793417f740c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'asd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'show'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6. \n",
    "#### Extrae una lista con peso total de cada barco, net_weight, sumando cada contenedor y agrupado por los campos ship_imo y container_group. Devuelve un DataFrame con la siguiente estructura: ship_imo, ship_name, container, total_net_weight.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data6 = data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ship_imo='AMC1861710', ship_name='Jayden', country='BD', departure='201602183', container_id='FCUK1755843', container_type='4960', container_group='28VH', net_weight='44804866.62', gross_weight='2240243.33', owner='Streich-Wilkinson', declared='Music, Tools, Automotive & Health', contact='octavia@stammbednar.name', customs_ok='true'),\n",
       " Row(ship_imo='POG1615575', ship_name='Lake Eribertoland', country='CR', departure='2016021611', container_id='PDXW1549639', container_type='28VH', container_group='8888', net_weight='16681047.32', gross_weight='500431.42', owner='Senger and Sons', declared='Movies & Jewelery', contact='cindy.dubuque@roberts.org', customs_ok='true')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data6new = data6.drop(\"country\", \"departure\", \"container_type\", \\\n",
    "                      \"container_group\", \"gross_weight\", \"owner\", \\\n",
    "                      \"declared\", \"customs_ok\", \"contact\", \"net_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------+\n",
      "|  ship_imo|         ship_name|container_id|\n",
      "+----------+------------------+------------+\n",
      "|AMC1861710|            Jayden| FCUK1755843|\n",
      "|POG1615575| Lake Eribertoland| PDXW1549639|\n",
      "|SQH1155999|            Aileen| PLKO1661930|\n",
      "|JCI1797526|          Herminio| BXMT1827488|\n",
      "|MBV1836745|Port Guiseppeburgh| JYIE1892741|\n",
      "|GYR1192020|         Emardland| LARQ1499256|\n",
      "|GLV1922612|           Eulalia| ARDX1463154|\n",
      "|NLH1771681|       Port Noemie| JFPX1246669|\n",
      "|FUS1202266|  East Mustafaland| ICAV1235470|\n",
      "|GLV1922612|           Eulalia| KEVU1145768|\n",
      "|IWE1254579|      North Creola| VDUQ1801278|\n",
      "|JET1053895|             Jamil| CXZN1286843|\n",
      "|KSP1096387|             Wiley| YAZN1142572|\n",
      "|GYR1192020|         Emardland| HVFU1799048|\n",
      "|GYR1192020|         Emardland| ROML1055099|\n",
      "|JMP1637582|East Zechariahland| LONM1299749|\n",
      "|TCU1641123|     New Margarete| XKAO1357085|\n",
      "|MBV1836745|Port Guiseppeburgh| JYPA1889923|\n",
      "|POG1615575| Lake Eribertoland| GKXC1181753|\n",
      "|AEY1108363|             Juana| GJFL14A2798|\n",
      "+----------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data6new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data6new = data6new.withColumn(\"total_net_weight\", lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         ship_name|\n",
      "+------------------+\n",
      "|         Emardland|\n",
      "|             Tiara|\n",
      "|East Zechariahland|\n",
      "| Lake Eribertoland|\n",
      "|             Jamil|\n",
      "|           Eulalia|\n",
      "|  East Mustafaland|\n",
      "|   New Santinoberg|\n",
      "|            Aileen|\n",
      "|            Jayden|\n",
      "|        Marksshire|\n",
      "|      North Creola|\n",
      "|       Port Noemie|\n",
      "|     New Margarete|\n",
      "|             Wiley|\n",
      "|   East Savanahton|\n",
      "|          Herminio|\n",
      "|Port Guiseppeburgh|\n",
      "|           Lomaton|\n",
      "|             Juana|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT ship_name FROM data\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mismo filtrado de datos en dos formas distintas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT container_id FROM data WHERE ship_name='Emardland' \").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.filter(data6['ship_name']=='Emardland').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    return str(x) + 'asd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'collect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-1ba03d35fe0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata6new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeachPartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'collect'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7.\n",
    "#### Guarda los resultados del ejercicio anterior en formato Parquet.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.\n",
    "#### ¿En qué casos crees que es más eficiente utilizar formatos como Parquet? ¿Existe alguna desventaja frente a formatos de texto como CSV?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Precio en AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9.\n",
    "#### ¿Es posible procesar XML mediante Spark? ¿Existe alguna restricción por la cual no sea eficiente procesar un único archivo en multiples nodos? ¿Se te ocurre alguna posible solución para trocear archivos suficientemente grandes? ¿Existe la misma problemática con otros formatos de texto como JSON?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sería posible mediante un librería externa (spark.read.xml que viene de databricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 10.\n",
    "#### Spark SQL tiene una función denominada avg que se utiliza para calcular el promedio de un conjunto de valores ¿Por qué los autores han creado esta función en lugar de usar el API estándar de Python o Scala?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
